---
title: "Getting Started with R"
author: "Austin K Lien"
date: "2024-02-06"
output: 
  html_document:
    # code_folding: hide
    df_print: "kable"
    toc: yes
    toc_float: yes
    toc_depth: 4
    toc_width: 1
    fig_retina: 2
    number_sections: no
    highlight: pygments
    theme: sandstone
    
  pdf_document:
    toc: yes
    toc_depth: '4'
---

# R and Rstudio 

**R is a programming language and environment for statistical and graphics.**

**RStudio is a powerful integrated development environment (IDE) specifically designed for R programming and provides a user-friendly interface that makes coding, data analysis, and report generation more efficient.**

Let's explore the key components of the RStudio environment:

- The **Source pane** (top left quadrant) is the main coding area
    - This is the central area where you write and edit your R code and where your R Markdown scripts take shape.
    - Output is also displayed here if Global Options for R Markdown are set to "Show output inline"
    
- The **Console pane** (bottom left quadrant) can be used to type and execute short interactive R commands such as installing packages.
  - This also serves as a place to monitor various messages, warnings, and errors generated during code execution.
  
- The **Environment pane** (top right quadrant) provides a snapshot of the current workspace, showing a list of R objects that are currently loaded into the R session.
  - Dataframes appear as tables that store data in rows and columns
    - these are fundamental structures for working with datasets
  - Variables are displayed with their name, type, and values.
  - Additional objects that can be displayed here are: lists, functions, vectors and matrices, factors, strings, and other user-defined objects.
    - *We will get into all this later*
    
- The **Output pane** (bottom left quadrant) serves as a central location for displaying various plots and visualizations generated during the R session in addition to other crucial information.
  - The file tab allows you to explore the files and directories in your current **working directory**.
  - The plots tab is dedicated to displaying graphical outputs generated by plotting functions.
  - The packages tab provides a list of installed packages in your R environment.
  - The help tab is where you can access documentation and help files for R functions, packages, and other topics
    - A shortcut for help is to highlight the specific function or command and press **f1**, use the a quotation mark (?) before the function or command, OR use 'help()'
  - The viewer tab is a spcae where certain types of interactive content of dynamic HTML outputs are displayed
  
  
  

# R Markdown

Why R Markdown?... R Markdown is a tool that allows a blend of R code with narrative text (like this!). 

**Markdown basics: syntax for formatting text**

YAML Header

- The YAML header in an R Markdown document is a section at the beginning of the file enclosed by three dashes (- - -). 
  - The YAML header is used to configure various settings for the R Markdown document, and it plays a crucial role in controlling the document's appearance and behavior when rendered.
  - Key elements are:
    - 'title' specifying the title of the document
    - 'author' specifying the author(s) of the document
    - 'output' specifying the desired output format, such as HTML, PDF, or word
    - Additional metadata can be added, such as table of contents (toc), and figure widths and heights.
    
HEADINGS AND SUBHEADINGS

- Headings serve as main titles or major section headings within a document and are added to the table of contents.
  - headings and subheadings are created by using hash symbols (#) and (##), respectively.  
    - Effective use of headings aids in document organization and navigation for both yourself and others (especially when you have thousands of lines of code).
    - keep headings concise AND descriptive and avoid adding additional styling (i.e., bold or italics).
    - Use headings and subheadings directly above chunks of code.
    
CODE CHUNKS

- Code chunks are fundamental elements in R Markdown documents that allow you to embed and execute R code within a document. 
  - Code chunks are enclosed by three backticks (```{r}) or by using the keyboard shortcut is **Ctrl + Alt + I**.
   - Options can also be included to control their behavior, such as silencing warnings (```{r warning = FALSE}) 
    -  or using (```{r include = FALSE} to omit the chunk from the rendered file.
- Using code chunks will break down your analysis into manageable sections.
  - Code within the chunk is executed when the R Markdown document is rendered ("Knit").The results of the code (output, plots, etc.) are displayed in the final document.
    - clicking on the "play" button on the top right area of the code chunk with execute only the one chunk.
    - pressing **Ctrl + Enter** will execute only the line you are on.
- The '**#**' character is also used to create comments *within a code chunk*. 
  - Comments are lines of text that are not executed as code; instead, they serve as annotations or explanations for the code. 
    - When used within a code chunk, comments are helpful for providing context, clarifying the purpose of the code, or adding explanatory notes.
    - It can also be used to hide code within the chunk if you don't want it to affect the final rendering

TEXT STYLING

- Text styling allows you to enhance the visual presentation of your document
  - *Adding asterisks around text will create italics*
  - **Adding double asterisks around text will create bold face font**
  - A par of tildes (~) will create subscripts (e.g., H~2~0)
  - A pair of carets (^) will create superscripts (e.g., Cu^2+^)
  - Block quotes can be added by using the greater-than symbol (>)

> "If we knew what it was we were doing, it wouldn't be called research"
>
> --- Albert Einstein 



  
# Creating strings, vectors, and dataframes

**Now that we've explored some formatting techniques, let's delve into the core of programming with R.**

In programming, a **string** is a sequence of characters, and it forms the backbone of many operations, from data manipulation to generating dynamic reports.

- A string in R is a sequence of characters which can be letters, numbers, symbols, or spaces.
  - Strings are created by using single or double quotes and can be assigned or named using the assignment operator '**<-**'. For example, 
  
  mystring <- "Hello world"
  
  
**Please keep in mind** 

- Everything is CASE-SENSITIVE; be careful when assigning names to data structures!  
- It is generally not recommended to have names that start with a number. 
  - While R allows column names to start with a number, it can lead to potential issues and may not work seamlessly with certain functions or packages. 


Also, when we render with R Markdown, we need to designate that it is written in the R language
  - We do this by placing our code inside a code chunk. Let's try it below.
  
```{r}
my_string <- "Hello World"

my_string
```


We can also combine, or concatenate strings to create new ones.
**Note:** pay attention to the Environment pane

```{r}
first <- "Austin"
first
last <- "Lien"
last

Name <- paste(first, last)
Name

```

Let's try another one.
```{r}
city <- "Crookston"
city
state <- "Minnesota"
state

location <- paste(city, state,
                  sep = ", ")
location

```


A **vector** is also a fundamental data structure in R that represents a one-dimensional array of elements

- Vectors are created using the '**c()**' function, which concatenates elements.
- Elements within a vector must be of the same data type (e.g., numeric, character, etc.)
  
Let's create some vectors below:

```{r}
names <- c("Alice", "Bob", "Charlie", "Derek", "Emily")
names

age <- c(31, 43, 28, 33, 27)
age

pronouns  <- c("She/Her", "He/Him", "They/Them", "He/Him", "She/Her")
pronouns
```

Now that we have created vectors, let's merge them into a data.frame

A **dataframe** is a two-dimensional data structure in R appearing as tables.

  - Dataframes consists of columns, each of which can be a different data type, arranged in rows
  - Essentially, they are collection of vectors, where each vector is a column in the data frame

```{r}
attendees <- data.frame(names, age, pronouns)

attendees
```

**Did you notice a new data structure appeared in the Environment Tab?**
 
- click on the new dataframe to view
- click on the blue arrow directly to the left of the dataframe name
  - Each variable is displayed with their name, type, and values.
  - Do you notice the $ symbol in front of the variables?
    - The '**$**' is used to extract specific columns or elements from a dataframe.
    
Let use the '$' to view the contents of the name column

```{r}
attendees$names
```



# Installing and loading packages

Installing packages in R is necessary to access additional functions and capabilities not included in the base R installation.

- To install a package, use the install.packages() function, providing the name of the package in quotes.
  - for example, install.packages("tidyverse")
  - you can also install multiple packages at once using a vector, for example, install.packages(c("dplyr", "ggplot2", "tidyr"))
  - installed packages will remain in the R file and shouldn't need to be installed again until you update R to a new version. 
- Once installed, packages need to be loaded into the R session before their functions can be used.
- To load a package, use the library() function, providing the name of the package *without* quotes.
  - Loading is done each time you start a new R session or when you want to use functions from a specific package
  - It's common to install and load packages at the beginning of your script 
    - I often use ```{r warning = FALSE, include = FALSE} in the code chunk to omit the code from the rendered file
    

**Below is a list and short descriptions of packages I commonly use.**

- **library(readxl)**
  - to read .xlsx (Excel) files

- **library(tidyverse)**
  - loads all core tidyverse packages
    - **ggplot2** - for data visualization
    - **dplyr** - for data manipulation
    - **tidyr** - for data tidying
    - **readr** - for data import
    - **tibble** - for "re-imagining" the dataframe
  - These packages can be installed and loaded separately as well.

- **library(kableExtra)**
  - Provides additional styling in rendered tables

- **library(ggpubr)**
- for "publication ready" data visualization
  - also, I find it easier than ggplot2 to create line graphs and scatter plots

Aesthetic packages 

- library(RColorBrewer)
  - Color palettes for color-blind friendly visuals
  
- library(scales)
  - transformation of scales in data visualization 

- library(extrafont)
  - For using other fonts in data visualization
  - This can be a pain to download, especially on University computers, but maybe it has change since the last time I did it.

Statistic analysis packages

- library(agricolae)
  - For post-hoc tests (e.g., LSD or HSD) for general linear models
  - For split-plot, split-split-plot, and strip-plot ANOVA.

- library(lme4) OR
- library(lmerTest)
  - For Mix-model ANOVA and assigning random effects
    - equivalent to PROC MIXED or PROC GLIMMIX in SAS

- library (emmeans)
  - For estimated marginal means (i.e., Least-squares means)
      - equivalent to LSMEANS of PROC GLIMMIX in SAS
      
- library(multcomp)
  - For compact letter display of emmeans output

- library(rstatix)
  - Additional statistics and correlation matrices

library(MASS)
- For BOX-COX transformations and other statistics
  - I've only had to use this once, other transformations (e.g., log10) usually do the trick


# Bringing in our own dataset

**Now that we've covered the basics of R, including its syntax, variables, data structures, and the essentials of packages, it's time to put this knowledge into practice by working with real data.**

Before we delve into working with our dataset, let's make sure we're in the right place. The working directory is the folder where R will look for files by default. To set the working directory, we use the '**setwd()**' function.

Setting the working directory is an important step when working with datasets in R. The working directory is the folder where R looks for and saves files. By setting the working directory, you make it easier to read and write files as you can refer to them by their relative paths.

Determining the file path for setting the working directory depends on your operating system and the location of the folder you want to use. 

In RStudio you can also go to the 'session' menu, select 'set working directory', click 'choose directory', and navigate to the desired folder in the file dialog.

- Once your chosen working directory is selected, the corresponding code and file path will appear on the console pane

  - **from here, you can copy and paste the code and file path to your RMarkdown script**


You can also navigate to the folder on your computer where the dataset is stored, or where you would like to save any files generated during your R session. 

 - Click on the folder's address bar, and it will display the full path. You can copy this path OR select'copy path' on the top left of the file explorer


- Use the **setwd()** function to specify the path to your chosen directory.
  - Be mindful of the slashes in your file path. Windows uses backslashes ( **'\'** ), and on macOS/Linux, use forward slashes ( **'/'** ).
  - **Make sure to change to forward slashes ( / ) for paths in R when using Windows.**
  - You can confirm that you've set the correct working directory by using the **getwd()** function.
  
 

```{r}
# setwd("C:/Users/lienx/Documents/2024-02-06 R Workshop")

setwd("G:/NWROC/SugarBeet_Pathology/R Workshop_2024_AKL")

getwd()
```

Now let's install and load the packages '**readxl**' and '**tidyverse**'

```{r}
# Install.packages('readxl')
# Install.packages('tidyverse')

library(readxl)
library(tidyverse)
``` 

Go to the **Files tab** in the Output pane. Do you see your Excel file? We can bring it into our environment using the '**read_excel()**' command from the readxl package.

**Note:** To import tab-delimited filed (.csv) use the 'read.csv()' function

```{r}
Assay <- read_excel(("2024-02-06 Data Set.xlsx"), 
                      sheet = "Soil Assays")
```

Check the environment, do you see your data frame?

Once the data is loaded, we can explore it to understand its structure and content several functions to get an initial overview

- **head()**: displays the first few rows
- **summary()**: displays summary statistics 
- **str()**: displays the structure of the data

```{r}

 # displays the first few rows
head(Assay)

# displays summary statistics 
summary(Assay)

# displays the structure of the data
str(Assay)
```

*Remember, if you don't want the output to show up in your final rendering, we can always do this in the console pane below.*
  
Now let's introduce **Factors**!

- A **factor** is a data structure used to represent distinct categories or levels.
- Most often, they are things like Treatments, Varieties, or Replications in an experiment

- the **as.factor()** function automatically identifies unique categories or levels 
- the **factor()** function is often used to specify custom levels using the '**level**' argument and allows you to rename them with the '**labels**' argument
  - **Be advised**, levels and labels need to be the same length and order.
    - In addition, the levels will appear alphabetically, even numbers (i.e., 1, 10, 2, 3)
- the **ordered()** function can be used similar to factor() but it is used to create an ordered factor where levels have a meaningful order
- **Note**: (If your variables long names, the **'\n'** argument can be used to create additional lines for each variable.
  

```{r}
Assay$Rep <- as.factor(Assay$Rep)

Assay$Trmt <- factor(Assay$Trmt, 
                    levels = c('kab', 'tach'),
                    labels = c("Kabina", "Tachigaren"))

Assay$Soil <- as.factor(Assay$Soil)

Assay$Year <- ordered(Assay$Year,
                      levels = c('2024', '2023'),
                      labels = c('2024', '2023'))
```

# Creating a boxplot 

**Now let's make our first figure!**

We will use the ggplot2 package to compare the Root Rot Index (**TotalRRI**) among the different **Soil** and **Trmt** using the *ggplot()** and *geom_boxplot()* arguments.

But let's first break down the components of 'ggplot()'
- **ggplot(data = my_data, aes(x = X, y = Y))**: This initializes the plot and sets the data and aesthetic mappings.
  - **data**: specifies the dataframe containing the variables to be plotted.
  - **aes()**: Aesthetic mappings define how variables in the dataset are mapped to visual properties.
    - Here, '**x**', '**y**', and '**fill**' aesthetics are mapped to specific variables.
  
- The '**+**' operator is used for adding additional layers to a plot, allowing you to build up a complex plot step by step.
  -  **+ geom_boxplot()** :creates a boxplot.
      - **width**: Controls the width of the boxes in the plot.
      - **color**: Sets the color of the outlines of the boxes.
        - colors can be specified either by name (e.g.: “red”) or by hexadecimal code (e.g. : “#FF1234”)
      - **alpha**: Adjusts the transparency of the boxes.
  - **+ facet_grid()** OR **facet_wrap**: Creates faceted plots to display multiple subsets of data into single plot.
  - **+ labs()**: Sets the titles for the plot and axes.
  - **+ theme_light()**:Specifies the overall appearance of the plot.
  - **theme()**: customizes the appearance of the plot and allows modifications to various aspects, such as axis labels, text size, legend placement, and more.
  
Similar principles apply to other types of plots in ggplot2. As you gain more experience with ggplot2, you'll discover additional options for fine-tuning your visualizations.


```{r}
# this initializes the plot
ggplot(
  
 #  specifies the dataframe containing the variables to be plotted  
  data = Assay,

        # aesthetics are mapped to specific variables
  #  The + operator is used for adding additional layers to a plot, allowing you to build up a complex plot step by step.
       aes(x=Soil, y = TotalRRI, fill = Trmt)) +
       
  
       
    #  creates a boxplot
  geom_boxplot(
  # Additional styling for the specifically the box plots
    width = 0.25,
    color = "black", 
    alpha = 0.8) +
    
  #  Creates faceted plots to display multiple subsets of data into single plot. 
  facet_wrap(~ Year, ncol = 2) +

  
  labs(x = "Location",
       y = "Root Rot Index (0-100)",
       title = "Root Rot Indices of disease nursery soils by year",
       fill = "Seed Treatment") +
  
  theme_light() +
  
  # changes visual aspects of labels and titles (all text besides axis text)
  theme(text = element_text(size = 15, 
                            face = "bold", 
                            color = "darkblue"),
        
       # changes visuals of axis text 
        axis.text.x = element_text(size = 10, 
                                   face = "italic", 
                                   color = "forestgreen",
                                   angle = 45,
                                   hjust = 0.5,
                                   vjust = 0.5),
        
        # element_blank() draws nothing and assigns no space
        axis.title.x = element_blank(),
        
        
        plot.title = element_text(hjust = 0.5, vjust = 1),
       
        # moves legend position
        legend.position = "bottom",
    
    
        legend.background = element_rect(color = "black", 
                                         fill = "lightgray", 
                                         linewidth = 0.5),
        plot.background = element_rect(color = "black", 
                                       fill = NA, 
                                       linewidth = 2)) +
  
   # sets values for discrete scale aesthetics - this staggers the x axis labels
  scale_x_discrete(guide = guide_axis(n.dodge = 2))
 
  
```

# Data manipulation

Now that we've covered the basics of creating and customizing visualizations in ggplot2, let's delve into an essential aspect of data manipulation: the difference between wide and long formats.

- **Wide Format**: Data is arranged with multiple variables as *columns*.
  - this format structure is straightforward and easy for humans to comprehend; however, it may not conform to the principles of tidy data and is difficult to work with for some statistical models and visualizations.
- **Long Format**: Data is arranged as *key-value pairs*.
  - this format structure allows for more flexibility in analysis and visualization; in addition, it easily accommodates a varying number of measurements or categories.
  
We'll now use '**pivot_longer()**' on a our Assay dataset to create a new dataframe where all root rot indices and transitioned from a wide to a long format.
  
- **data**: the data frame to be reshaped.
- **cols: a vector specifying the columns to pivot into longer format.
- **names_to**: specifies the name of the new column that will store the **variable names** from the original wide format.
- **values_to**: specifies the name of the new column that will store the **values** associated with each variable.

**Let's also order our root rot indices**

```{r}
Assay_long <- pivot_longer(data = Assay,
                           col = c("TotalRRI", "AphRRI", "RhizRRI"),
                           names_to = "RRI_Type",
                           values_to = "Index_Value")

Assay_long$RRI_Type <- ordered(Assay_long$RRI_Type,
                     levels = c("TotalRRI", "AphRRI", "RhizRRI"),
                     labels = c("Total\nRoot Rot",
                                "Aphanomyces\nRoot Rot",
                                "Rhizoctonia\nRoot Rot"))
```

**Now let's make a new boxplot that shows each of the Root Rot Indices on the x axis and we will facet by Year and Soil using facet_grid**

```{r}
ggplot(data = Assay_long,
       aes(x=RRI_Type, y = Index_Value, fill = Trmt)) +
  geom_boxplot(width = 0.5, color = "black", alpha = 0.8) +
  facet_grid(Soil ~ Year) +
  labs(x = "Root Rot Index Type",
       y = "Root Rot Index (0-100)",
       title = "Root Rot Indices of disease nursery soils by year",
       fill = "Seed Treatment") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 7.5))
```

# Creating more plots (ggpubr)

Now that we've covered the fundamentals of creating visualizations with ggplot2, let's explore **ggpubr**, an extension package that takes our plotting capabilities to the next level. **ggpubr** is designed to make it easier to create complex and publication-ready plots with additional functionalities.

While ggplot2 is a versatile and powerful plotting package for a wide range of tasks, ggpubr serves as a convenient extension when the goal is to quickly generate aesthetically pleasing, publication-ready plots with minimal manual adjustments. 

Let's first install and load in the packages **ggpubr** and **RColorBrewer**

```{r}
# install.packages(c("ggpubr", "RColorBrewer"))

library(ggpubr)


library(RColorBrewer)

# displays all RColorBrewer palettes
display.brewer.all()

# Another color palette package
library(viridis)

```

## ggpubr boxplot


Let's make a box and whisker plot  of our root rot indices and add error bars and value labels using **ggboxplot()** from the ggpubr package. 

- Take note of the minor differences when setting up the plot
  - To view all options and how to use them, use the **help tab** 
- Note that all variables are in quotations
    - This also allows us to access column names that have spaces in them or columns that start with numbers
- Once the plot is set up, we can add ggplot2 objects to it

Let's also change the color palette using the **scale_fill_brewer(palette = )** function from the RColorBrewer package. 

```{r}
ggboxplot(Assay_long,
          x = "RRI_Type",
          y = "Index_Value",
          fill = "Trmt",
          facet.by = "Soil", ncol = 2) +
  scale_fill_brewer(palette = "Dark2") +
  
  theme(axis.text.x = element_text(size = 15)) +
  
  
# sets values for discrete scale aesthetics - this staggers the x axis labels  
  scale_x_discrete(guide = guide_axis(n.dodge = 2))



```


## ggpubr barplot

Let's make a bar plot  of our root rot indices and add error bars and value labels using **ggbarplot()** from the ggpubr package. 

    
```{r}
ggbarplot(Assay_long,
          x = "RRI_Type",
          y = "Index_Value",
          fill = "Trmt",
          
          
          # slightly different than ggplot2          
          facet.by = c("Soil", "Year"), nrow = 2,

          # BOTH 'add = "mean",' AND 'position = position_dodge(1)' NEED TO BE USED FOR BARPLOTS
          # This adds standard error bars 
          add = 'mean_se',
          
          # this separates the columns, rather than being stacked
          position = position_dodge(0.8),
          
          
          
          # these control the data labels
          label = TRUE,
          lab.size = 4,
          lab.vjust = 0.5,
          lab.nb.digits = 1,
          
          # We can change these titles here, but not the legend title
          xlab = "Root Rot Index Type",
          ylab = "Root Rot Index (0-100)",
          title = "Root Rot Indices of disease nursery soils by year"
          
          ) +
  
   labs(fill = "Seed Treatment") + 
  
  # This comes from the RColorBrewer Package
  scale_fill_brewer(palette = "Dark2") +
    
    
  theme(axis.text.x = element_text(size = 7.5),
        
        # You can place the legend anywhere within the plot using a vector
        legend.position = c(0.9,0.9)) 
        
    

```

## ggpubr boxplot and jitter

**Let's try a different plot with ggpubr**

- We will use **ggboxplot()** from the ggpubr package
- I am also introducing **jitter** points and manually changing shapes or colors

```{r}

ggboxplot(Assay,
          x = "Soil",
          y = "AphRRI",
          fill = "Soil",
          add = "jitter",
          
          # this is adding jitter points according to treatment
          # we could also assign the color          
          add.params = list(shape = "Trmt"),
          ) +
  
# This manually changed the jitter shapes (shape = )   
scale_shape_manual(values = c(2,3)) +

# This changed the boxplot (fill = ) color  
scale_fill_manual(values = c("salmon", "cyan"))

```

**We can also view the distribution of the data using a violin plot**

## violin plot
```{r}
ggviolin(Assay, 
          x = "Trmt",
          add = 'jitter',
          fill = "Soil",
          y = "AphRRI",
          add.params = list(shape = "Year",
                            fill = "Soil")) +
  scale_shape_manual(values = c(2,4))
```


## ggpubr line graph

Now, let's create line graphs using **ggline()** to display trends and patterns over a continuous variable, making them suitable for time series data or any data with a natural ordering.

The columns labelled c('DAP_6', 'DAP_14', 'DAP_21', 'DAP_28') are Days After Planting (DAP).

The data within the these columns are the number of living plants expressed as a percentage of the total number of planted. The column 

**First, we need to create a new data.frame and use pivot_longer() to transpose these columns. We can also rename our values within our new column and make sure they are in the correct order**


```{r}
Assay_plants <- pivot_longer(Assay,
                             cols = c('DAP_6', 'DAP_14', 'DAP_21', 'DAP_28'),
                             names_to = "DAP",
                             values_to = "plants")

Assay_plants$DAP <- ordered(Assay_plants$DAP,
                            levels = c('DAP_6', 'DAP_14', 'DAP_21', 'DAP_28'),
                            labels = c('6','14','21','28'))
```

Now, we can use **ggline()** to create a line graph with DAP on the x axis. 

- I will also introduce the **guides()** argument to customize labels in our legend and **rremove()** to remove specific components from a plot.

```{r, warning=FALSE, message=FALSE}
ggline(Assay_plants,
       x = "DAP",
       y = "plants",
       group = "Trmt",
       color = 'Trmt',
       linetype = 'Trmt',
       shape = "Trmt",
       
       
       # without adding 'add = mean' or another variation, the line graph will not be logical       
       add = c('mean_se'),

       facet.by = 'Soil',
       
       # creates both lines and points
       plot_type = 'b',
       
       # this changes the size of the points
       point.size = 1.2,
       
       
       ylab = "Plant Stand (%)",
       xlab = "Days after planting",
       
       
       # makes x axis as numeric (i.e., logical spacing between values)
       numeric.x.axis = TRUE
       
       ) +
  
  theme_bw() +
  
  theme(text = element_text(
                            # family = "Times New Roman", 
                            # we can use the family argument once you install and load the 'extrafont' package
                            size = 12, 
                            face = "bold",
                            color = "black"),
        axis.text.x = element_text(angle = 0, 
                                   size = 10, 
                                   color = "black", 
                                   vjust = 0.5, 
                                   hjust = 0.5),
        legend.position = "bottom",
        
        # This changes the width inside the legend, making them easier to distinguish
        legend.key.width = unit(1.5, "cm")) +
        
  # rremove can be used to remove a specific component from a plot      
  rremove('legend.title') +
  
  # guides can be used to customize legends   
  guides(color = guide_legend(nrow = 2)) +
 
    
  scale_color_brewer(palette = 'Set2')
```


## ggpubr scatter plot

We will now use **ggscatter()** to visualize the relationship between RhizRRI and AphRRI

```{r}
ggscatter(Assay_plants, 
          x= "RhizRRI", 
          y = "AphRRI",
          
          # displays regression line
          add = "reg.line", 
          
          # displays buffer around regression line representing confidence interval
          conf.int = TRUE,
          
          # displays correlation coefficient, size, and method
          cor.coef = TRUE,
          cor.coef.size = 10,
          cor.method = "pearson",
          
          # moves the location of the data displayed in the plot
          cor.coef.coord = c(50, 75)
          
          )
```

**Now, let's see if there is difference among the soils.**

- We will need to use **stat_cor()** argument for displaying the coefficients for each treatment.
  - ggscatter will display both lines but will only display one coefficient. 
  
```{r}
ggscatter(Assay_plants, 
          x= "RhizRRI", 
          y = "AphRRI",
          
         # Displays regression lines and confidence interval for each factor signified by color 
          color="Trmt",
          add = "reg.line", 
          conf.int = TRUE,
          )+
        
  # extension of ggpubr to further customize correlation stats, here we are displaying the coefficients for each Trmt.
  stat_cor(aes(color = Trmt), 
           method = "pearson", 
           label.x = 40,
           digits = 3)
  
  

```


# Piping and Creating Tables 

Tables are essential for presenting detailed data summaries and results, especially in research and data analysis.

the package **kableExtra** simplifies the creation of aesthetically pleasing and customizable tables, enhancing the presentation of summary statistics and other tabular data.

- kable() is a function from the knitr package, and it is primarily used for converting data frames into markdown or LaTeX tables.
  - It provides basic functionality for formatting tables, such as aligning columns, setting column names, and applying basic formatting options.
  - **kableExtra** is an extension package that builds upon kable() to provide additional customization options and formatting capabilities for tables with many arguments hidden in the background
    -  this allows for more advanced customization of tables, making it suitable for creating publication-quality tables with complex formatting requirements.

```{r}
library(kableExtra)

# creates a table with auto formatting 
kbl(Assay)
  
```


**But to go any further, I need to introduce piping!**

- Piping simplifies the process of performing multiple operations on data by passing the output of one function directly as the input to another function.
  - The pipe operator **%>%** is used to chain operations together. 
    - It takes the output of the expression on its left-hand side and feeds it as the first argument to the function on its right-hand side.
    - Piping makes code more readable and easier to understand, especially when performing multiple transformations on data.
    - It reduces the need for intermediate variables and allows for more compact code.
    - Piping is commonly used in data manipulation, data wrangling, and analysis workflows, where multiple operations are performed sequentially on datasets.
    - The keyboard shortcut is **Ctrl+Shft+M**

```{r}

kbl(Assay) %>% 
  
  # uses the built-in bootstrap themes by default 
  kable_classic(full_width = F, html_font = "Arial")
  
```

We can also take our dataframe and pipe directly into the kbl() function and add some additional styling

```{r}

Assay %>% 
  
# sets number of digits after the decimal point for all numbers  
kbl(digits = 1) %>%
  
  
  kable_classic(full_width = F, html_font = "Arial") %>% 
  
  # provides a clean approach to modify the style of HTML tables
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))
 
```



# Getting summary statistics 

Summary statistics provide valuable insights into the characteristics and distributions of the data.

**rstatix** offers a convenient way to compute various summary statistics, such as means, medians, standard deviations, and correlations, streamlining the data analysis process.

```{r}
library(rstatix)

Assay %>%
get_summary_stats(type="common")
```

**However, this table won't look to good once we knit our code, so let's use what we learned with kableExtra to make it look better**

```{r}
Assay %>%
  
# common designates the type of summary statistics (many other options are available)  
get_summary_stats(type="common") %>% 
  
  
kbl(digits = 1) %>%
    kable_classic(full_width = F, html_font = "Arial") %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))
```

**Looks better right?**

Now what if we want to get summary stats just for a few variables?

```{r}
Assay %>%
get_summary_stats(c(TotalRRI, AphRRI, RhizRRI), type="common")  %>% 

kbl(digits = 1) %>% kable_classic(full_width = F, html_font = "Arial")
```

But what if we want to get the summary statistics for each treatment, soil, or year?

# Introducing dplyr and statistical syntax

**dplyr** and tidyr provide a set of intuitive functions for manipulating data frames, making it ideal for tasks such as filtering, summarizing, mutating, and arranging data.
  
  - dplyr and tidyr should already be loaded with tidyverse, but you can load it separately as well.
    - **group_by()** can be used to group data by one or more variables.
      - ungroup() removes grouping.
    - **filter()** can be used to subset your data based on specific criteria.
      - subset() can also be used to subset data (from base R)
    - **rename()** will rename columns. 
    - **summarise()** is used to compute specific summary statistics within each group.
      - *I prefer using rstatix*
    - **mutate()** can create new variables based on existing ones or modify existing variables.
   - Use **arrange()** to sort data based on one or more variables.
      - Continue to use the pipe operator %>% to chain together multiple dplyr operations in a single line, promoting readability and conciseness.
  - **seperate()** turns a single character column into multiple columns 
  
  
By mastering the functions provided by dplyr, you can streamline your data analysis workflow and gain greater control over your data processing tasks

Statistical operators in R are commonly used for performing various statistical calculations, hypothesis testing, and modeling. Here's an overview of some common statistical operators and their syntax in R:

COMPARISON OPERATORS

- x == y  # Equals
- x != y  # Not equals
- x > y   # Greater than
- x < y   # Less than
- x >= y  # Greater than or equal to
- x <= y  # Less than or equal to
- a :  z  # Spans between start and end



LOGICAL OPERATORS 

- x & y   # AND
- x | y   # OR
- !x      # NOT




STATISTCAL FUNCTIONS

- mean(x)      # Mean
- sd(x)        # Standard deviation
- median(x)    # Median
- cor(x, y)    # Correlation coefficient
- quantile(x)  # Quantiles



**Okay, now let's group by Soil and get some summary statistics!**

```{r}
Assay %>%
  
  # converts to group
  group_by(Soil) %>% 
  
# changed stats type to show only mean and standard deviation  
get_summary_stats(TotalRRI, type= c("mean_sd"))  %>% 

  
kbl(digits = 1) %>% kable_classic(full_width = F, html_font = "Arial")
```

**We can also group by both Soil AND Trmt and look at only the mean and standard error Root rot indices**

```{r}
Assay %>%
  group_by(Soil:Trmt) %>% 
  get_summary_stats(c(TotalRRI, AphRRI, RhizRRI), type="mean_se")  %>%
  kbl(digits = 1) %>% kable_classic(full_width = F, html_font = "Arial")
```

**Now let's use the filter() function to look at only 2024 data**

```{r}
Assay %>% filter(Year == "2024") %>%
  group_by(Soil:Trmt) %>% 
  get_summary_stats(c(TotalRRI), type="mean_se")  %>%
  kbl(digits = 1) %>% kable_classic(full_width = F, html_font = "Arial")
```

**Let do only 2024 AND NOT the kabina treatment** 

```{r}
Assay %>% dplyr::filter(Year == "2024" & Trmt != "Kabina") %>% 
  group_by(Soil:Trmt) %>% 
  get_summary_stats(c(TotalRRI), type="mean_se")  %>%
  kbl(digits = 1) %>% kable_classic(full_width = F, html_font = "Arial")
```

**OR we can remove the kabina treatment from just the 2023 trial**; this is done by the OR operator.

```{r}
Assay %>% filter(Year == "2024" | Trmt == "Tachigaren") %>% 
  group_by(Soil:Trmt) %>% 
  get_summary_stats(c(TotalRRI), type="mean_se")  %>%
  kbl(digits = 1) %>% kable_classic(full_width = F, html_font = "Arial")
```


**REMINDER: Rather than creating new strings for everything, you can also pipe this directly into summary statistics!**

**Now lets put it all together to create another table**

```{r, warning=FALSE, message=FALSE}
Assay %>%
  group_by(Year:Soil:Trmt) %>% 
  get_summary_stats(c(TotalRRI, AphRRI, RhizRRI), type="common") %>% 
  
  dplyr::select(c('Year:Soil:Trmt', variable, mean)) %>%
  
  separate(col = 'Year:Soil:Trmt',
           into = c('Year', 'Soil', 'Trmt'),
           sep = ":") %>% 
  
  pivot_wider(
    names_from = variable,
    values_from = c(mean)) %>% 
  rename('Soil Location' = Soil,
         'Seed Treatment' = Trmt) %>% 
  
  filter(Year == "2024") %>% 

  kbl(digits = 1) %>%
    kable_classic(full_width = F, html_font = "Times New Roman") %>% 
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))
```

**We can even go futher...just bare with me!** 

```{r, warning=FALSE, message=FALSE}
Assay %>%
  filter(Year == "2024") %>% 
  group_by(Soil:Trmt) %>% 
  get_summary_stats(c(TotalRRI, AphRRI, RhizRRI), type="common") %>% 
  
  dplyr::select(c('Soil:Trmt', variable, mean, se)) %>% 
 
  # mutates the variable 'mean' by using the function to round the number to one digit after the decimal 
  mutate_at(vars(mean), funs(round(., 1))) %>% 
  
  # mutates the variable standard error
  mutate_at(vars(se), funs(round(., 2))) %>% 
  
  # takes the standard error column and pastes the plus/minus sign before the number and parenthesis around the everything
  mutate(se = paste0("(±", se, ")")) %>% 
  
  # take the new standard error column and pastes it after the mean column
  mutate(mean = paste(mean, se, sep = " "))  %>% 
  
  # drops se column
  dplyr::select(-se) %>% 
  
  
  separate(col = 'Soil:Trmt',
           into = c('Soil', 'Trmt'),
           sep = ":") %>% 
  
  pivot_wider(
    names_from = variable,
    values_from = c(mean)) %>% 
  rename('Soil Location' = Soil,
         'Seed Treatment' = Trmt) %>% 

  kbl() %>%
    kable_classic(full_width = F, html_font = "Times New Roman") %>% 
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))
```

# Manipulating plots

## ordering by mean
```{r}
Assay2 <- Assay

Assay2$All_Trmt <- paste(Assay2$Year, 
                         Assay2$Soil, 
                         Assay2$Trmt,
                        sep = ':')

Assay2$All_Trmt <- with(Assay2, 
                        
# This reorders our treatment column by descending means of AphRRI                        
                        reorder(All_Trmt, -AphRRI, mean))


ggboxplot(Assay2,
          x = "All_Trmt",
          y = "AphRRI",
          fill = "All_Trmt") +
  theme(legend.position = "none") +
  scale_fill_brewer(palette = "Dark2") +
  
  theme(axis.text.x = element_text(size = 8, 
                                   angle = 90,
                                   hjust = 1,
                                   vjust = 0.5)) +
  
  stat_summary(fun = mean, geom = "point",
               
               # adds shape representing mean
               shape = 1, size = 2)
  
```



## dropping outliers

Here we are creating a boxplot to visualize any outliers 

```{r, warning=FALSE, message=FALSE}
ggboxplot(Assay, 
          y = "RhizRRI",
          ylab = "Rhizoc Root Rot")
```

In ggplot2, an observation is defined as an outlier if it meets one of the following two requirements: The observation is 1.5 times the interquartile range less than the first quartile (Q1) The observation is 1.5 times the interquartile range greater than the third quartile (Q3).

Based on the figure, we can see that there are 7 dots representing outliers

```{r, warning=FALSE, message=FALSE}
# This shows us the dimensions of our data fram (48 observations across 11 variables
dim(Assay)

# here we are defining the first and third quartiles
quartiles <- quantile(Assay$RhizRRI, probs = c(.25, .75), na.rm = FALSE)

# This is defining the interquartile range
IQR <- IQR(Assay$RhizRRI)

# This is setting our lower limit
lower <- quartiles[1] - 1.5*IQR

# This is setting our upper limit
upper <- quartiles[2] + 1.5*IQR

# Here we are keeping data that is greater than the lower limit and less than the upper limit
RhizRRI_No_outliers <- filter(Assay, Assay$RhizRRI > lower & Assay$RhizRRI < upper)

# Dimensions show that we now have only 41 observations
dim(RhizRRI_No_outliers)


RhizRRI_ONLY_outliers <- subset(Assay, Assay$RhizRRI <= lower | Assay$RhizRRI >= upper)
dim(RhizRRI_ONLY_outliers)
```


# Analysis of Variance Models

```{r}
library(agricolae)

library(lme4) 
# OR
library(lmerTest)

library(emmeans)

library(rcompanion)

```


## ANOVA (CRD) two-way factorial treatment structure

The two following models are identical

```{r}
# This signifies and ANOVA for Aph RRI in response to Soil and Trmt and the interaction between Soil and Trmt
# THIS IS THE SAME as below

# Using summary() allows use to see the output of the ANOVA model
# We also need to name the model so we can use it later on
model_1 <- aov(AphRRI ~ Soil + Trmt + Soil:Trmt, data = Assay)


summary(model_1)



model_2 <- aov(AphRRI ~ Soil*Trmt, data = Assay)
summary(model_2)

```


## ANOVA (RCBD) two-way factorial treatment structure
```{r}

# This adds a blocking factor to the interaction between Soil and Trmt and main effects
# BE WARNED: This is not a mixed model! this is still a generalized linear model
model_3 <- aov(AphRRI ~ Rep + Soil*Trmt, data = Assay)


summary(model_3)
```


## LSD and HSD with agricolae

```{r}
library(agricolae)

model <- aov(AphRRI ~ Soil*Trmt + Rep, Assay)
summary(model)

# Using LSD.test() performs Fisher's least significant difference
LSD.test(model, 
         trt = 'Trmt',
         
         # alpha changes your significance level; default is 0.05)
         alpha = 0.1,
         console=TRUE)


LSD.test(model, 
         trt = 'Soil',
         console=TRUE)

LSD.test(model, 
         trt = c('Soil', 'Trmt'), 
         console = TRUE)
```

## Checking assumptions and transformations 


In linear regression analysis, it's crucial to check the assumptions underlying the model to ensure that the results are valid and reliable. Two of the key assumptions that are often checked are the normality of the residuals and the homoscedasticity (constant variance) of the residuals. Here's why it's important to check these assumptions and how histograms and formal tests can be used:

- Normality of Residuals:
  - One of the assumptions in linear regression is that the residuals (the differences between observed and predicted values) are normally distributed.
  - The normality assumption is important because many statistical tests and confidence intervals associated with linear regression models rely on the normality of residuals.
  - Checking for normality can be done visually using histograms of the residuals. A histogram of residuals that closely resembles a bell-shaped curve suggests normality.
  - Formal tests for normality, such as the Shapiro-Wilk test or the Kolmogorov-Smirnov test, can also be performed to assess whether the residuals significantly deviate from a normal distribution.
  - histograms can also be used to visualize normality
  
- Homoscedasticity (Constant Variance) of Residuals:
  - Another assumption in linear regression is that the variance of the residuals is constant across all levels of the independent variables. This is known as homoscedasticity.
  - Homoscedasticity is important because unequal variances (heteroscedasticity) can lead to biased estimates of regression coefficients and incorrect standard errors, affecting the validity of statistical inference.
  - Visual inspection of residuals versus fitted values plot or residuals versus predictor variable plots can help detect patterns indicating non-constant variance. A horizontal band of points around zero suggests homoscedasticity.
  - Formal tests for homoscedasticity, such as the Breusch-Pagan test or the White test, can be conducted to statistically evaluate whether the variance of the residuals is constant across different levels of the independent variables.
- By checking these assumptions, particularly through the use of histograms for normality and diagnostic plots/tests for homoscedasticity, researchers can identify potential violations of the assumptions and take appropriate steps to address them. This may involve data transformation, using robust regression techniques, or considering alternative modeling approaches. Ensuring that the assumptions are met helps to maintain the reliability and validity of the regression analysis results.

- Levene's test and the Breusch-Pagan test are both statistical tests used to assess the homogeneity of variance assumption in regression analysis. However, they differ in their approach and application:
  - Levene's test is a non-parametric test used to assess the equality of variances across groups or treatments.
    - It compares the absolute deviations of individual observations from the group mean (or median) to evaluate whether these deviations are similar across groups.
    - Levene's test does not assume normality of the data, making it robust against violations of normality assumptions.
    - It is often used in the context of analysis of variance (ANOVA) to check the homogeneity of variances assumption before proceeding with further analysis.
  - The Breusch-Pagan test is a parametric test used specifically in the context of regression analysis to assess the homoscedasticity assumption.
    - Homoscedasticity refers to the condition where the variance of the errors/residuals is constant across all levels of the independent variables.
    - The Breusch-Pagan test assesses whether the variance of the residuals in a regression model is dependent on the independent variables. If significant, it suggests heteroscedasticity, meaning the variance of the residuals is not constant across the range of values of the independent variables.
    - It is commonly used after running a regression model to check whether the assumptions of the linear regression model are met.

```{r, warning=FALSE, message=FALSE}
library(car)
library(MASS) 

# Creates density plot of given data values - similar to hist()
ggdensity(Assay$AphRRI)

# Creates histogram of given data values - similar to ggdensity()
hist(Assay$AphRRI)

# Quantile-Comparison Plot of empirical quantiles of a variable
qqPlot(Assay$AphRRI)

# Creates a linear model of Trmt and Soil main effects and interactions with of added blocking factor of the interaction between Replication and Year
model <- aov(AphRRI ~ Trmt*Soil + Rep:Year, data = Assay)

# Plots studentized residuals from a linear model
qqPlot(model)

# Performs the Shapiro-Wilk test of normality
# null hypothesis is that the sample has been generated from normal distribution
shapiro.test(residuals(model))

# Computes Levene's test for homogeneity of variance across the specified group(s).
leveneTest(lm(AphRRI ~ Soil*Trmt, data = Assay))

# computes score test for non-constant error variance
# another test for nonconstant variance called the Breusch-Pagan test
ncvTest(lm(AphRRI ~ Soil*Trmt, data = Assay))

# plots residuals vs fitted values 
plot(model, 1)

# Creates qq-plot of standardized residuals
plot(model, 2)

# creates scale-location plot - similar to residuals vs fitted plot
plot(model, 3)

# Plots Cook's distance, a measure of the influence of each individual data point (outliers)
plot(model, 4)

# assesses the presence of influential observations or outliers within each level of a categorical predictor variable
plot(model, 5)




```

**Generally, lines in the model plots should be straight and/or fitted to be normal and homoscedastic**


lets try a power transformation and see if that resolves our violation of constant variance


```{r}
model <- aov(AphRRI^3 ~ Trmt*Soil + Rep:Year, data = Assay)

hist(Assay$AphRRI^3)

shapiro.test(residuals(model))

leveneTest(lm(AphRRI^3 ~ Soil*Trmt, data = Assay))

ncvTest(lm(AphRRI^3 ~ Soil*Trmt, data = Assay))

plot(model, 1)
plot(model, 2)
plot(model, 3)
plot(model, 4)
plot(model, 5)

```



## Split-plot with agricolae

```{r}
model <- with(Assay, sp.plot(Rep:Year, Soil,Trmt,AphRRI))

gla<-model$gl.a
glb<-model$gl.b
Ea<-model$Ea 
Eb<-model$Eb


with(Assay, LSD.test(AphRRI,Soil, gla, Ea, 
                     console=TRUE))
with(Assay, LSD.test(AphRRI,Trmt, glb, Eb, 
                     console=TRUE))
with(Assay, LSD.test(AphRRI, Soil:Trmt, glb, Eb, 
                     console=TRUE))

```


## Mixed-model with lmerTest and emmeans

```{r}
library(lmerTest)
library(emmeans)
```


```{r}
# 1 | x signifies random effect
# the mixed model needs to be named so we can bring it into the next step

model <- lmer(DAP_6 ~ Soil * Trmt + (1 | Year:Rep), data= Assay)


anova(model) %>%  kbl() %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))
```



```{r}
# creates LSMEANS i.e., Estimated marginal means
fit <- emmeans(model, list(pairwise ~ Soil:Trmt), adjust = "none")

# adds compact letter display for EMMEANS
cld <- multcomp::cld(object = fit$emmeans,
                           Letters = letters)


kbl(cld) %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))
```



# Advanced tables for summary statistics

```{r}
model <- lmer(DAP_6 ~ Soil * Trmt + (1 | Rep)*(1 | Year), data= Assay)
anova(model) %>%  kbl() %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))


# Here we are grabbing the p value for the interactions (3rd line)
pval_DAP_6_int <- anova(model)$"Pr(>F)"[3]%>%  round(digits = 4) 


fit <- emmeans(model, list(pairwise ~ Soil:Trmt), adjust = "none")
cld <- multcomp::cld(object = fit$emmeans,
                           Letters = letters)
kbl(cld) %>% kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))


cld_DAP_6_int <- cld %>% 
  
  # this creates new table with only the variables, emmean, and letter group
  dplyr::select(c('Soil', 'Trmt', emmean, .group)) %>% 
  
  # this rounds the emmean to a whole number
  mutate_at(vars(emmean), funs(round(., 0))) %>% 
  
  # this creates a new column with both emmean and letter group
  mutate(emmean = paste(emmean, .group, sep = " "))  %>% 
  
  # this drops the letter group column
  dplyr::select(-.group) %>% 
  
  # this renames the emmean column
  rename('DAP_6' = emmean) %>% 
  
  # this sorts our table so we can merge it with the next one.
  arrange(., Soil, Trmt)
   
```

```{r}
model <- lmer(DAP_14 ~ Soil * Trmt + (1 | Rep)*(1 | Year), data= Assay)
anova(model) %>%  kbl() %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))

pval_DAP_14_int <- anova(model)$"Pr(>F)"[3]%>%  round(digits = 4)  

fit <- emmeans(model, list(pairwise ~ Soil:Trmt), adjust = "none")
cld <- multcomp::cld(object = fit$emmeans,
                           Letters = letters)
kbl(cld) %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))

cld_DAP_14_int <- cld %>% 
  dplyr::select(c('Soil', 'Trmt', emmean, .group)) %>% 
  mutate_at(vars(emmean), funs(round(., 0))) %>% 
  mutate(emmean = paste(emmean, .group, sep = " "))  %>% 
  dplyr::select(-.group) %>% 
  rename('DAP_14' = emmean) %>% 
  arrange(., Soil, Trmt)
```

```{r}
model <- lmer(DAP_21 ~ Soil * Trmt + (1 | Rep)*(1 | Year), data= Assay)
anova(model) %>%  kbl() %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))

pval_DAP_21_int <- anova(model)$"Pr(>F)"[3]%>%  round(digits = 4) 

fit <- emmeans(model, list(pairwise ~ Soil:Trmt), adjust = "none")
cld <- multcomp::cld(object = fit$emmeans,
                           Letters = letters)
kbl(cld) %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))

cld_DAP_21_int <- cld %>% 
  dplyr::select(c('Soil', 'Trmt', emmean, .group)) %>% 
  mutate_at(vars(emmean), funs(round(., 0))) %>% 
  mutate(emmean = paste(emmean, .group, sep = " "))  %>% 
  dplyr::select(-.group) %>% 
  rename('DAP_21' = emmean) %>% 
  arrange(., Soil, Trmt)
```

```{r warning = FALSE}
model <- lmer(DAP_28 ~ Soil * Trmt + (1 | Rep)*(1 | Year), data= Assay)
anova(model) %>%  kbl() %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))

pval_DAP_28_int <- anova(model)$"Pr(>F)"[3]%>%  round(digits = 4) 


fit <- emmeans(model, list(pairwise ~ Soil:Trmt), adjust = "none")
cld <- multcomp::cld(object = fit$emmeans,
                           Letters = letters)
kbl(cld) %>%
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))

cld_DAP_28_int <- cld %>% 
  dplyr::select(c('Soil', 'Trmt', emmean, .group)) %>% 
  mutate_at(vars(emmean), funs(round(., 0))) %>% 
  mutate(emmean = paste(emmean, .group, sep = " "))  %>% 
  dplyr::select(-.group) %>% 
  rename('DAP_28' = emmean) %>% 
  arrange(., Soil, Trmt)
```


```{r}

# this creates a row containing our p values
pval <- (c(" ", "p-value", pval_DAP_6_int, pval_DAP_14_int, 
           pval_DAP_21_int, pval_DAP_28_int))


```



## emmeans, letter grouping, and pvalue

```{r, warning=FALSE, message=FALSE}
Assay %>%
  group_by(Soil:Trmt) %>% 
  get_summary_stats(c(DAP_6, DAP_14, DAP_21, DAP_28), type="common") %>% 
  
  dplyr::select(c('Soil:Trmt', variable, mean, se)) %>% 
  
  mutate_at(vars(mean), funs(round(., 1))) %>% 
  mutate_at(vars(se), funs(round(., 2))) %>% 
  mutate(se = paste0("(±", se, ")")) %>% 
  mutate(mean = paste(mean, se, sep = " "))  %>% 
  dplyr::select(-se) %>% 
  
  separate(col = 'Soil:Trmt',
           into = c('Soil', 'Trmt'),
           sep = ":") %>% 
  
  pivot_wider(
    names_from = variable,
    values_from = c(mean)) %>% 
  rename('Soil Location' = Soil,
         'Seed Treatment' = Trmt) %>% 
  rbind(., pval) %>% 

  kbl() %>%
    kable_classic(full_width = F, html_font = "Times New Roman") %>% 
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))
```

With Compact Letter Display

```{r}
cld_DAP_6_int %>% 
  dplyr::left_join(cld_DAP_14_int, by = c('Soil', 'Trmt')) %>% 
  dplyr::left_join(cld_DAP_21_int, by = c('Soil', 'Trmt')) %>% 
  dplyr::left_join(cld_DAP_28_int, by = c('Soil', 'Trmt')) %>% 
  mutate(Soil = as.character(Soil)) %>% 
  mutate(Trmt = as.character(Trmt)) %>%  
rbind(., pval) %>% 

 kbl() %>%
    kable_classic(full_width = F, html_font = "Times New Roman") %>% 
  kable_styling(bootstrap_options = c("hover", "condensed", "responsive"))
```






